{"cells":[{"cell_type":"markdown","metadata":{"id":"iQgF1b9ZyMZH"},"source":["# **OBJECT DETECTION MODELS applied to nuImages**\n","\n","## **Transfer Learning with TensorFlow 2.x**\n","\n","**This notebook is part of the BTTAI Challenge 2023**\n","\n","In this phase of the project, we will be training a custom detector for pedestrians using pretrained models. We will do transfer learning to achieve this."]},{"cell_type":"markdown","metadata":{"id":"ORo9oGPiA8k7"},"source":["## **OUTLINE**\n","\n","### **Part 1: Testing models (COMPLETED IN PREVIOUS NOTEBOOK)**\n","\n","* Import and/or install libraries needed\n","\n","* Import tensorflow models to test\n","\n","* Install the TensorFlow Object Detection API\n","\n","* Read images from the nuImages sample folder\n","\n","* Test object detection with given model\n","\n","\n","\n","### **Part 2: Train and evaluate a model with transfer learning (this notebook)**\n","\n","* Import libraries\n","\n","* Create custom folder structure\n","\n","* Collect the dataset of images and label them to get their xml files\n","\n","* Generate the TFRecord files required for training\n","\n","* Edit the model pipeline config file and download the pre-trained model checkpoint\n","\n","* Train and evaluate the model\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tzu_KTz6gpEz"},"source":["## **Part 2: Transfer learning using a pretrained object detection model**"]},{"cell_type":"markdown","metadata":{"id":"pnK5qi3gXqlE"},"source":["## **1) Import Libraries**"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"background_save":true},"executionInfo":{"elapsed":5833,"status":"ok","timestamp":1701540643888,"user":{"displayName":"Vanessa Bellotti","userId":"09344672906555327481"},"user_tz":300},"id":"R1Fl0K9TVJ50"},"outputs":[],"source":["import os\n","import glob\n","import cv2 as cv2\n","import numpy as np\n","import xml.etree.ElementTree as ET\n","import pandas as pd\n","import tensorflow as tf\n"]},{"cell_type":"markdown","metadata":{"id":"92GABWQa1eYT"},"source":["## **2) Create custom folder structure in Google Drive**\n","We will be using Google Drive to store all files needed to run these tests. Do the following:\n","\n","* Create a folder named ***nuImg_customOD*** in your google drive.\n","\n","* Create two folders inside the ***nuImg_customOD*** folder:\n","\n"," -- One folder named ***training*** (this is where the checkpoints will be saved during training)\n","\n"," -- Another folder named ***data*** (this is where we will add all images and annotations used for training)\n"]},{"cell_type":"markdown","metadata":{"id":"ca4Hv2sT4lt-"},"source":["### **Create and upload your image files and xml files.**\n"," Inside the folder ***data*** create a folder named ***images*** for your custom dataset images and create another folder named ***annotations*** for its corresponding xml files.\n","\n","Remember the xml files are expected to have PASCAL_VOC XML format.\n","\n","Next, upload the files to the corresponding  ***nuImg_customOD/data/*** folder (or upload .zip files and we will unzip them in Step 4)  \n","\n","\n"," Note: All image files should have extension as \".jpg\" - this is because we want to save disk space. This will be useful as we need to generate the TensorFlow records later\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"OLsPGJiuxRrK"},"source":["##**4) Mount drive and link your folder**"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24766,"status":"ok","timestamp":1701540668647,"user":{"displayName":"Vanessa Bellotti","userId":"09344672906555327481"},"user_tz":300},"id":"RhZoiRBoqnju","outputId":"e9ff2eea-b422-4e09-a8ab-2c3778b435d5"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/gdrive\n"," Applications\n","'Colab Notebooks'\n","'Cool restaurants.gsheet'\n","'Food Finances.gsheet'\n","'High School'\n"," l1Rocket-altitudeVStime.jpg\n"," l1rocketDesign.pdf\n"," label_map.pbtxt\n","'MathWorks #2 (BOS) - Classify Object Behavior to Enhance the Safety of Autonomous Vehicles'\n","'My Drive'\n","'Personal Projects'\n"," test_labels.csv\n"," train_labels.csv\n"," Tufts\n","'Vanessa Bellotti headshot.jpg'\n","/content/gdrive/.shortcut-targets-by-id/1V6R5dIPvEZICGv8F8ogtd3KU8lk3Bltk/MathWorks #2 (BOS) - Classify Object Behavior to Enhance the Safety of Autonomous Vehicles\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","\n","# this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n","!ln -s \"/content/gdrive/My Drive/\" /mydrive\n","!ls /mydrive\n","%cd /mydrive/MathWorks\\ \\#2\\ \\(BOS\\)\\ -\\ Classify\\ Object\\ Behavior\\ to\\ Enhance\\ the\\ Safety\\ of\\ Autonomous\\ Vehicles/\n","shared_folder_path = '/content/drive/Shared drives/SharedFolderName'"]},{"cell_type":"markdown","metadata":{"id":"rHnTmrSwNg6S"},"source":["### **Optional: Unzip files**  \n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E9XEg1kpSj4N"},"outputs":[],"source":["# Uncomment the following lines of code and run if you uploaded .zip files\n","\n","## unzip the datasets and their contents so that they are now in /mydrive/customTF2/data/ folder\n","#!unzip /mydrive/nuImg_customOD/images.zip -d .\n","#!unzip /mydrive/nuImg_customOD/annotations.zip -d ."]},{"cell_type":"markdown","metadata":{"id":"9D1UNW7c9O-I"},"source":["## **5) Clone the tensorflow models and test the model builder**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"nKXwP1ZJMz6w"},"outputs":[{"name":"stdout","output_type":"stream","text":["fatal: destination path 'models' already exists and is not an empty directory.\n","/content/gdrive/.shortcut-targets-by-id/1V6R5dIPvEZICGv8F8ogtd3KU8lk3Bltk/MathWorks #2 (BOS) - Classify Object Behavior to Enhance the Safety of Autonomous Vehicles/models/research\n","Processing /content/gdrive/.shortcut-targets-by-id/1V6R5dIPvEZICGv8F8ogtd3KU8lk3Bltk/MathWorks #2 (BOS) - Classify Object Behavior to Enhance the Safety of Autonomous Vehicles/models/research\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting avro-python3 (from object-detection==0.1)\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting apache-beam (from object-detection==0.1)\n","  Downloading apache_beam-2.52.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.7/14.7 MB\u001b[0m \u001b[31m83.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (9.4.0)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (4.9.3)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.7.1)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (3.0.6)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (21.6.0)\n","Requirement already satisfied: tf-slim in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.1.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.16.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.0.7)\n","Collecting lvis (from object-detection==0.1)\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.11.4)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (1.5.3)\n","Collecting tf-models-official\u003e=2.5.1 (from object-detection==0.1)\n","  Downloading tf_models_official-2.15.0-py2.py3-none-any.whl (2.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow_io (from object-detection==0.1)\n","  Downloading tensorflow_io-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (28.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from object-detection==0.1) (2.14.0)\n","Collecting pyparsing==2.4.7 (from object-detection==0.1)\n","  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.8/67.8 kB\u001b[0m \u001b[31m998.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting sacrebleu\u003c=2.2.0 (from object-detection==0.1)\n","  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.6/116.6 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting portalocker (from sacrebleu\u003c=2.2.0-\u003eobject-detection==0.1)\n","  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu\u003c=2.2.0-\u003eobject-detection==0.1) (2023.6.3)\n","Requirement already satisfied: tabulate\u003e=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu\u003c=2.2.0-\u003eobject-detection==0.1) (0.9.0)\n","Requirement already satisfied: numpy\u003e=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu\u003c=2.2.0-\u003eobject-detection==0.1) (1.23.5)\n","Collecting colorama (from sacrebleu\u003c=2.2.0-\u003eobject-detection==0.1)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from tf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (0.5.0)\n","Requirement already satisfied: google-api-python-client\u003e=1.6.7 in /usr/local/lib/python3.10/dist-packages (from tf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (2.84.0)\n","Collecting immutabledict (from tf-models-official\u003e=2.5.1-\u003eobject-detection==0.1)\n","  Downloading immutabledict-4.0.0-py3-none-any.whl (4.5 kB)\n","Requirement already satisfied: kaggle\u003e=1.3.9 in /usr/local/lib/python3.10/dist-packages (from tf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (1.5.16)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.10/dist-packages (from tf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (4.1.3)\n","Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from tf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (4.8.1.78)\n","Requirement already satisfied: psutil\u003e=5.4.3 in /usr/local/lib/python3.10/dist-packages (from tf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (5.9.5)\n","Requirement already satisfied: py-cpuinfo\u003e=3.3.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (9.0.0)\n","Requirement already satisfied: pyyaml\u003e=6.0.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (6.0.1)\n","Collecting sentencepiece (from tf-models-official\u003e=2.5.1-\u003eobject-detection==0.1)\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting seqeval (from tf-models-official\u003e=2.5.1-\u003eobject-detection==0.1)\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/dist-packages (from tf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (4.9.3)\n","Requirement already satisfied: tensorflow-hub\u003e=0.6.0 in /usr/local/lib/python3.10/dist-packages (from tf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (0.15.0)\n","Collecting tensorflow-model-optimization\u003e=0.4.1 (from tf-models-official\u003e=2.5.1-\u003eobject-detection==0.1)\n","  Downloading tensorflow_model_optimization-0.7.5-py2.py3-none-any.whl (241 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m241.2/241.2 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-text~=2.15.0 (from tf-models-official\u003e=2.5.1-\u003eobject-detection==0.1)\n","  Downloading tensorflow_text-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow~=2.15.0 (from tf-models-official\u003e=2.5.1-\u003eobject-detection==0.1)\n","  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil\u003e=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003eobject-detection==0.1) (2.8.2)\n","Requirement already satisfied: pytz\u003e=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas-\u003eobject-detection==0.1) (2023.3.post1)\n","Requirement already satisfied: absl-py\u003e=0.2.2 in /usr/local/lib/python3.10/dist-packages (from tf-slim-\u003eobject-detection==0.1) (1.4.0)\n","Collecting crcmod\u003c2.0,\u003e=1.7 (from apache-beam-\u003eobject-detection==0.1)\n","  Downloading crcmod-1.7.tar.gz (89 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting orjson\u003c4,\u003e=3.9.7 (from apache-beam-\u003eobject-detection==0.1)\n","  Downloading orjson-3.9.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill\u003c0.3.2,\u003e=0.3.1.1 (from apache-beam-\u003eobject-detection==0.1)\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: cloudpickle~=2.2.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam-\u003eobject-detection==0.1) (2.2.1)\n","Collecting fastavro\u003c2,\u003e=0.23.6 (from apache-beam-\u003eobject-detection==0.1)\n","  Downloading fastavro-1.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fasteners\u003c1.0,\u003e=0.3 (from apache-beam-\u003eobject-detection==0.1)\n","  Downloading fasteners-0.19-py3-none-any.whl (18 kB)\n","Requirement already satisfied: grpcio!=1.48.0,\u003c2,\u003e=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam-\u003eobject-detection==0.1) (1.59.3)\n","Collecting hdfs\u003c3.0.0,\u003e=2.1.0 (from apache-beam-\u003eobject-detection==0.1)\n","  Downloading hdfs-2.7.3.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: httplib2\u003c0.23.0,\u003e=0.8 in /usr/local/lib/python3.10/dist-packages (from apache-beam-\u003eobject-detection==0.1) (0.22.0)\n","Collecting js2py\u003c1,\u003e=0.74 (from apache-beam-\u003eobject-detection==0.1)\n","  Downloading Js2Py-0.74-py3-none-any.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: jsonschema\u003c5.0.0,\u003e=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam-\u003eobject-detection==0.1) (4.19.2)\n","Collecting objsize\u003c0.7.0,\u003e=0.6.1 (from apache-beam-\u003eobject-detection==0.1)\n","  Downloading objsize-0.6.1-py3-none-any.whl (9.3 kB)\n","Requirement already satisfied: packaging\u003e=22.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam-\u003eobject-detection==0.1) (23.2)\n","Collecting pymongo\u003c5.0.0,\u003e=3.8.0 (from apache-beam-\u003eobject-detection==0.1)\n","  Downloading pymongo-4.6.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (677 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m677.1/677.1 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: proto-plus\u003c2,\u003e=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache-beam-\u003eobject-detection==0.1) (1.22.3)\n","Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,\u003c4.26.0,\u003e=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache-beam-\u003eobject-detection==0.1) (3.20.3)\n","Requirement already satisfied: pydot\u003c2,\u003e=1.2.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam-\u003eobject-detection==0.1) (1.4.2)\n","Requirement already satisfied: requests\u003c3.0.0,\u003e=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam-\u003eobject-detection==0.1) (2.31.0)\n","Requirement already satisfied: typing-extensions\u003e=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam-\u003eobject-detection==0.1) (4.5.0)\n","Collecting zstandard\u003c1,\u003e=0.18.0 (from apache-beam-\u003eobject-detection==0.1)\n","  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pyarrow\u003c12.0.0,\u003e=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache-beam-\u003eobject-detection==0.1) (9.0.0)\n","Collecting pyarrow-hotfix\u003c1 (from apache-beam-\u003eobject-detection==0.1)\n","  Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n","Requirement already satisfied: cycler\u003e=0.10.0 in /usr/local/lib/python3.10/dist-packages (from lvis-\u003eobject-detection==0.1) (0.12.1)\n","Requirement already satisfied: kiwisolver\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from lvis-\u003eobject-detection==0.1) (1.4.5)\n","Requirement already satisfied: opencv-python\u003e=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from lvis-\u003eobject-detection==0.1) (4.8.0.76)\n","Requirement already satisfied: contourpy\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003eobject-detection==0.1) (1.2.0)\n","Requirement already satisfied: fonttools\u003e=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib-\u003eobject-detection==0.1) (4.45.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem==0.34.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow_io-\u003eobject-detection==0.1) (0.34.0)\n","Requirement already satisfied: google-auth\u003c3.0.0dev,\u003e=1.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client\u003e=1.6.7-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (2.17.3)\n","Requirement already satisfied: google-auth-httplib2\u003e=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client\u003e=1.6.7-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (0.1.1)\n","Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,\u003c3.0.0dev,\u003e=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client\u003e=1.6.7-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (2.11.1)\n","Requirement already satisfied: uritemplate\u003c5,\u003e=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client\u003e=1.6.7-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (4.1.1)\n","Collecting docopt (from hdfs\u003c3.0.0,\u003e=2.1.0-\u003eapache-beam-\u003eobject-detection==0.1)\n","  Downloading docopt-0.6.2.tar.gz (25 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tzlocal\u003e=1.2 in /usr/local/lib/python3.10/dist-packages (from js2py\u003c1,\u003e=0.74-\u003eapache-beam-\u003eobject-detection==0.1) (5.2)\n","Collecting pyjsparser\u003e=2.5.1 (from js2py\u003c1,\u003e=0.74-\u003eapache-beam-\u003eobject-detection==0.1)\n","  Downloading pyjsparser-2.7.1.tar.gz (24 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: attrs\u003e=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003c5.0.0,\u003e=4.0.0-\u003eapache-beam-\u003eobject-detection==0.1) (23.1.0)\n","Requirement already satisfied: jsonschema-specifications\u003e=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003c5.0.0,\u003e=4.0.0-\u003eapache-beam-\u003eobject-detection==0.1) (2023.11.1)\n","Requirement already satisfied: referencing\u003e=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003c5.0.0,\u003e=4.0.0-\u003eapache-beam-\u003eobject-detection==0.1) (0.31.1)\n","Requirement already satisfied: rpds-py\u003e=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema\u003c5.0.0,\u003e=4.0.0-\u003eapache-beam-\u003eobject-detection==0.1) (0.13.2)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from kaggle\u003e=1.3.9-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (2023.11.17)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle\u003e=1.3.9-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (4.66.1)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle\u003e=1.3.9-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (8.0.1)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle\u003e=1.3.9-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (2.0.7)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle\u003e=1.3.9-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (6.1.0)\n","Collecting dnspython\u003c3.0.0,\u003e=1.16.0 (from pymongo\u003c5.0.0,\u003e=3.8.0-\u003eapache-beam-\u003eobject-detection==0.1)\n","  Downloading dnspython-2.4.2-py3-none-any.whl (300 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.4/300.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer\u003c4,\u003e=2 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3.0.0,\u003e=2.24.0-\u003eapache-beam-\u003eobject-detection==0.1) (3.3.2)\n","Requirement already satisfied: idna\u003c4,\u003e=2.5 in /usr/local/lib/python3.10/dist-packages (from requests\u003c3.0.0,\u003e=2.24.0-\u003eapache-beam-\u003eobject-detection==0.1) (3.6)\n","Requirement already satisfied: astunparse\u003e=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (1.6.3)\n","Requirement already satisfied: flatbuffers\u003e=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (23.5.26)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,\u003e=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (0.5.4)\n","Requirement already satisfied: google-pasta\u003e=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (0.2.0)\n","Requirement already satisfied: h5py\u003e=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (3.9.0)\n","Requirement already satisfied: libclang\u003e=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (16.0.6)\n","Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (0.2.0)\n","Requirement already satisfied: opt-einsum\u003e=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (3.3.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (67.7.2)\n","Requirement already satisfied: termcolor\u003e=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (2.3.0)\n","Requirement already satisfied: wrapt\u003c1.15,\u003e=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (1.14.1)\n","Collecting tensorboard\u003c2.16,\u003e=2.15 (from tensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1)\n","  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting tensorflow-estimator\u003c2.16,\u003e=2.15.0 (from tensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1)\n","  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting keras (from object-detection==0.1)\n","  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-model-optimization\u003e=0.4.1-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (0.1.8)\n","Requirement already satisfied: pyasn1\u003e=0.1.7 in /usr/local/lib/python3.10/dist-packages (from oauth2client-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (0.5.1)\n","Requirement already satisfied: pyasn1-modules\u003e=0.0.5 in /usr/local/lib/python3.10/dist-packages (from oauth2client-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (0.3.0)\n","Requirement already satisfied: rsa\u003e=3.1.4 in /usr/local/lib/python3.10/dist-packages (from oauth2client-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (4.9)\n","Requirement already satisfied: scikit-learn\u003e=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (1.2.2)\n","Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (0.5.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (8.1.7)\n","Requirement already satisfied: etils[enp,epath,etree]\u003e=0.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (1.5.2)\n","Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (2.3)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (1.14.0)\n","Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (0.10.2)\n","Requirement already satisfied: wheel\u003c1.0,\u003e=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse\u003e=1.6.0-\u003etensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (0.42.0)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]\u003e=0.9.0-\u003etensorflow-datasets-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (2023.6.0)\n","Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]\u003e=0.9.0-\u003etensorflow-datasets-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (6.1.1)\n","Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath,etree]\u003e=0.9.0-\u003etensorflow-datasets-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (3.17.0)\n","Requirement already satisfied: googleapis-common-protos\u003c2.0.dev0,\u003e=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,\u003c3.0.0dev,\u003e=1.31.5-\u003egoogle-api-python-client\u003e=1.6.7-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (1.61.0)\n","Requirement already satisfied: cachetools\u003c6.0,\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth\u003c3.0.0dev,\u003e=1.19.0-\u003egoogle-api-python-client\u003e=1.6.7-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (5.3.2)\n","Requirement already satisfied: joblib\u003e=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn\u003e=0.21.3-\u003eseqeval-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (1.3.2)\n","Requirement already satisfied: threadpoolctl\u003e=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn\u003e=0.21.3-\u003eseqeval-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (3.2.0)\n","Requirement already satisfied: google-auth-oauthlib\u003c2,\u003e=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.16,\u003e=2.15-\u003etensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (1.0.0)\n","Requirement already satisfied: markdown\u003e=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.16,\u003e=2.15-\u003etensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (3.5.1)\n","Requirement already satisfied: tensorboard-data-server\u003c0.8.0,\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.16,\u003e=2.15-\u003etensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (0.7.2)\n","Requirement already satisfied: werkzeug\u003e=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard\u003c2.16,\u003e=2.15-\u003etensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (3.0.1)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach-\u003ekaggle\u003e=1.3.9-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (0.5.1)\n","Requirement already satisfied: text-unidecode\u003e=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify-\u003ekaggle\u003e=1.3.9-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (1.3)\n","Requirement already satisfied: requests-oauthlib\u003e=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib\u003c2,\u003e=0.5-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (1.3.1)\n","Requirement already satisfied: MarkupSafe\u003e=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug\u003e=1.0.1-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (2.1.3)\n","Requirement already satisfied: oauthlib\u003e=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib\u003e=0.7.0-\u003egoogle-auth-oauthlib\u003c2,\u003e=0.5-\u003etensorboard\u003c2.16,\u003e=2.15-\u003etensorflow~=2.15.0-\u003etf-models-official\u003e=2.5.1-\u003eobject-detection==0.1) (3.2.2)\n","Building wheels for collected packages: object-detection, avro-python3, crcmod, dill, hdfs, seqeval, pyjsparser, docopt\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1697356 sha256=1cdc3783cc75e8e910b3415e12ed4b04f261eb0a81b3eef1dcc156a8032e3110\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-wbottn2_/wheels/90/93/08/f206daa23590e8beac4c2f910439590dfcf7f01b79e97f94a5\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=43992 sha256=99c408d72875c8593c5a5f6696a9b69ad93e46df9a0c8971e46caaa66bbc87ec\n","  Stored in directory: /root/.cache/pip/wheels/bc/85/62/6cdd81c56f923946b401cecff38055b94c9b766927f7d8ca82\n","  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31405 sha256=4968a29a64070ecc33bc0eda463ca390c413699d05160493ea852fd71b0a4e9e\n","  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78540 sha256=0c8b1552d38be7ed963336adb5830705573e6151b25fd762244d40f2c80f5c25\n","  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n","  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34325 sha256=7e70d962f3acf727a1bd869f9e7a405dd5f63cd9c3a4ed81cd52a98f40fd6d45\n","  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=bd793543fc7d68e7088bb854c9f53e33fb05cbc669a01825db4968935cce2df5\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n","  Building wheel for pyjsparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pyjsparser: filename=pyjsparser-2.7.1-py3-none-any.whl size=25984 sha256=90d2413daad663ade44db14ac25ecd28bd8c94e7edf5906daf9a84199be82f90\n","  Stored in directory: /root/.cache/pip/wheels/5e/81/26/5956478df303e2bf5a85a5df595bb307bd25948a4bab69f7c7\n","  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=4338f33f29eab8cec4946dca64e58200f16fca50f312621c46268c9a3622948b\n","  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n","Successfully built object-detection avro-python3 crcmod dill hdfs seqeval pyjsparser docopt\n","Installing collected packages: sentencepiece, pyjsparser, docopt, crcmod, zstandard, tensorflow-model-optimization, tensorflow_io, tensorflow-estimator, pyparsing, pyarrow-hotfix, portalocker, orjson, objsize, keras, js2py, immutabledict, fasteners, fastavro, dnspython, dill, colorama, avro-python3, sacrebleu, pymongo, hdfs, seqeval, lvis, tensorboard, apache-beam, tensorflow, tensorflow-text, tf-models-official, object-detection\n","  Attempting uninstall: tensorflow-estimator\n","    Found existing installation: tensorflow-estimator 2.14.0\n","    Uninstalling tensorflow-estimator-2.14.0:\n","      Successfully uninstalled tensorflow-estimator-2.14.0\n","  Attempting uninstall: pyparsing\n","    Found existing installation: pyparsing 3.1.1\n","    Uninstalling pyparsing-3.1.1:\n","      Successfully uninstalled pyparsing-3.1.1\n","  Attempting uninstall: keras\n","    Found existing installation: keras 2.14.0\n","    Uninstalling keras-2.14.0:\n","      Successfully uninstalled keras-2.14.0\n","  Attempting uninstall: tensorboard\n","    Found existing installation: tensorboard 2.14.1\n","    Uninstalling tensorboard-2.14.1:\n","      Successfully uninstalled tensorboard-2.14.1\n","  Attempting uninstall: tensorflow\n","    Found existing installation: tensorflow 2.14.0\n","    Uninstalling tensorflow-2.14.0:\n","      Successfully uninstalled tensorflow-2.14.0\n","Successfully installed apache-beam-2.52.0 avro-python3-1.10.2 colorama-0.4.6 crcmod-1.7 dill-0.3.1.1 dnspython-2.4.2 docopt-0.6.2 fastavro-1.9.0 fasteners-0.19 hdfs-2.7.3 immutabledict-4.0.0 js2py-0.74 keras-2.15.0 lvis-0.5.3 object-detection-0.1 objsize-0.6.1 orjson-3.9.10 portalocker-2.8.2 pyarrow-hotfix-0.6 pyjsparser-2.7.1 pymongo-4.6.1 pyparsing-2.4.7 sacrebleu-2.2.0 sentencepiece-0.1.99 seqeval-1.2.2 tensorboard-2.15.1 tensorflow-2.15.0 tensorflow-estimator-2.15.0 tensorflow-model-optimization-0.7.5 tensorflow-text-2.15.0 tensorflow_io-0.34.0 tf-models-official-2.15.0 zstandard-0.22.0\n"]}],"source":["# clone the tensorflow models on the colab cloud vm\n","!git clone --q https://github.com/tensorflow/models.git\n","\n","#navigate to /models/research folder to compile protos\n","%cd models/research\n","\n","# Compile protos.\n","!protoc object_detection/protos/*.proto --python_out=.\n","\n","# Install TensorFlow Object Detection API.\n","!cp object_detection/packages/tf2/setup.py .\n","!python -m pip install ."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"St1r_0-w9jqI"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-12-02 18:28:47.275880: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-02 18:28:47.275935: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-02 18:28:47.277513: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-02 18:28:48.290420: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","2023-12-02 18:28:53.104802: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n","Skipping registering GPU devices...\n","Running tests under Python 3.10.12: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","WARNING:tensorflow:`tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n","W1202 18:28:53.141966 136091472269312 batch_normalization.py:1531] `tf.keras.layers.experimental.SyncBatchNormalization` endpoint is deprecated and will be removed in a future release. Please use `tf.keras.layers.BatchNormalization` with parameter `synchronized` set to True.\n","W1202 18:28:53.435384 136091472269312 model_builder.py:1112] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.65s\n","I1202 18:28:53.761752 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 0.65s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.61s\n","I1202 18:28:54.370170 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.61s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.34s\n","I1202 18:28:54.714538 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.34s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.48s\n","I1202 18:28:55.197210 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.48s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.47s\n","I1202 18:28:57.667062 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 2.47s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I1202 18:28:57.678870 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","I1202 18:28:57.705746 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","I1202 18:28:57.723456 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","I1202 18:28:57.741988 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.11s\n","I1202 18:28:57.850920 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.11s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n","I1202 18:28:57.959739 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.11s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n","I1202 18:28:58.074540 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.11s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.12s\n","I1202 18:28:58.191674 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.12s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.11s\n","I1202 18:28:58.301377 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.11s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","I1202 18:28:58.336987 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I1202 18:28:58.545970 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I1202 18:28:58.546128 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 64\n","I1202 18:28:58.546201 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 3\n","I1202 18:28:58.548890 136091472269312 efficientnet_model.py:143] round_filter input=32 output=32\n","I1202 18:28:58.579537 136091472269312 efficientnet_model.py:143] round_filter input=32 output=32\n","I1202 18:28:58.579657 136091472269312 efficientnet_model.py:143] round_filter input=16 output=16\n","I1202 18:28:58.670023 136091472269312 efficientnet_model.py:143] round_filter input=16 output=16\n","I1202 18:28:58.670165 136091472269312 efficientnet_model.py:143] round_filter input=24 output=24\n","I1202 18:28:58.889189 136091472269312 efficientnet_model.py:143] round_filter input=24 output=24\n","I1202 18:28:58.889350 136091472269312 efficientnet_model.py:143] round_filter input=40 output=40\n","I1202 18:28:59.105630 136091472269312 efficientnet_model.py:143] round_filter input=40 output=40\n","I1202 18:28:59.105824 136091472269312 efficientnet_model.py:143] round_filter input=80 output=80\n","I1202 18:28:59.449437 136091472269312 efficientnet_model.py:143] round_filter input=80 output=80\n","I1202 18:28:59.449611 136091472269312 efficientnet_model.py:143] round_filter input=112 output=112\n","I1202 18:28:59.775130 136091472269312 efficientnet_model.py:143] round_filter input=112 output=112\n","I1202 18:28:59.775303 136091472269312 efficientnet_model.py:143] round_filter input=192 output=192\n","I1202 18:29:00.239852 136091472269312 efficientnet_model.py:143] round_filter input=192 output=192\n","I1202 18:29:00.240021 136091472269312 efficientnet_model.py:143] round_filter input=320 output=320\n","I1202 18:29:00.361679 136091472269312 efficientnet_model.py:143] round_filter input=1280 output=1280\n","I1202 18:29:00.429992 136091472269312 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1202 18:29:00.488382 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I1202 18:29:00.488551 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 88\n","I1202 18:29:00.488625 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 4\n","I1202 18:29:00.490720 136091472269312 efficientnet_model.py:143] round_filter input=32 output=32\n","I1202 18:29:00.509135 136091472269312 efficientnet_model.py:143] round_filter input=32 output=32\n","I1202 18:29:00.509262 136091472269312 efficientnet_model.py:143] round_filter input=16 output=16\n","I1202 18:29:00.673499 136091472269312 efficientnet_model.py:143] round_filter input=16 output=16\n","I1202 18:29:00.673661 136091472269312 efficientnet_model.py:143] round_filter input=24 output=24\n","I1202 18:29:00.962230 136091472269312 efficientnet_model.py:143] round_filter input=24 output=24\n","I1202 18:29:00.962430 136091472269312 efficientnet_model.py:143] round_filter input=40 output=40\n","I1202 18:29:01.474095 136091472269312 efficientnet_model.py:143] round_filter input=40 output=40\n","I1202 18:29:01.474256 136091472269312 efficientnet_model.py:143] round_filter input=80 output=80\n","I1202 18:29:01.895804 136091472269312 efficientnet_model.py:143] round_filter input=80 output=80\n","I1202 18:29:01.895960 136091472269312 efficientnet_model.py:143] round_filter input=112 output=112\n","I1202 18:29:02.291930 136091472269312 efficientnet_model.py:143] round_filter input=112 output=112\n","I1202 18:29:02.292196 136091472269312 efficientnet_model.py:143] round_filter input=192 output=192\n","I1202 18:29:02.832260 136091472269312 efficientnet_model.py:143] round_filter input=192 output=192\n","I1202 18:29:02.832428 136091472269312 efficientnet_model.py:143] round_filter input=320 output=320\n","I1202 18:29:03.205964 136091472269312 efficientnet_model.py:143] round_filter input=1280 output=1280\n","I1202 18:29:03.294355 136091472269312 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1202 18:29:03.416936 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I1202 18:29:03.417124 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 112\n","I1202 18:29:03.417206 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 5\n","I1202 18:29:03.420475 136091472269312 efficientnet_model.py:143] round_filter input=32 output=32\n","I1202 18:29:03.446698 136091472269312 efficientnet_model.py:143] round_filter input=32 output=32\n","I1202 18:29:03.446867 136091472269312 efficientnet_model.py:143] round_filter input=16 output=16\n","I1202 18:29:03.648239 136091472269312 efficientnet_model.py:143] round_filter input=16 output=16\n","I1202 18:29:03.648431 136091472269312 efficientnet_model.py:143] round_filter input=24 output=24\n","I1202 18:29:04.016012 136091472269312 efficientnet_model.py:143] round_filter input=24 output=24\n","I1202 18:29:04.016226 136091472269312 efficientnet_model.py:143] round_filter input=40 output=48\n","I1202 18:29:04.457560 136091472269312 efficientnet_model.py:143] round_filter input=40 output=48\n","I1202 18:29:04.457758 136091472269312 efficientnet_model.py:143] round_filter input=80 output=88\n","I1202 18:29:05.057532 136091472269312 efficientnet_model.py:143] round_filter input=80 output=88\n","I1202 18:29:05.057724 136091472269312 efficientnet_model.py:143] round_filter input=112 output=120\n","I1202 18:29:05.689669 136091472269312 efficientnet_model.py:143] round_filter input=112 output=120\n","I1202 18:29:05.689892 136091472269312 efficientnet_model.py:143] round_filter input=192 output=208\n","I1202 18:29:06.585465 136091472269312 efficientnet_model.py:143] round_filter input=192 output=208\n","I1202 18:29:06.585660 136091472269312 efficientnet_model.py:143] round_filter input=320 output=352\n","I1202 18:29:06.989454 136091472269312 efficientnet_model.py:143] round_filter input=1280 output=1408\n","I1202 18:29:07.082953 136091472269312 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1202 18:29:07.199634 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I1202 18:29:07.199894 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 160\n","I1202 18:29:07.199996 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 6\n","I1202 18:29:07.204298 136091472269312 efficientnet_model.py:143] round_filter input=32 output=40\n","I1202 18:29:07.238310 136091472269312 efficientnet_model.py:143] round_filter input=32 output=40\n","I1202 18:29:07.238484 136091472269312 efficientnet_model.py:143] round_filter input=16 output=24\n","I1202 18:29:07.480612 136091472269312 efficientnet_model.py:143] round_filter input=16 output=24\n","I1202 18:29:07.480833 136091472269312 efficientnet_model.py:143] round_filter input=24 output=32\n","I1202 18:29:07.857117 136091472269312 efficientnet_model.py:143] round_filter input=24 output=32\n","I1202 18:29:07.857287 136091472269312 efficientnet_model.py:143] round_filter input=40 output=48\n","I1202 18:29:08.147612 136091472269312 efficientnet_model.py:143] round_filter input=40 output=48\n","I1202 18:29:08.147798 136091472269312 efficientnet_model.py:143] round_filter input=80 output=96\n","I1202 18:29:08.692183 136091472269312 efficientnet_model.py:143] round_filter input=80 output=96\n","I1202 18:29:08.692359 136091472269312 efficientnet_model.py:143] round_filter input=112 output=136\n","I1202 18:29:09.254577 136091472269312 efficientnet_model.py:143] round_filter input=112 output=136\n","I1202 18:29:09.254755 136091472269312 efficientnet_model.py:143] round_filter input=192 output=232\n","I1202 18:29:10.001834 136091472269312 efficientnet_model.py:143] round_filter input=192 output=232\n","I1202 18:29:10.001995 136091472269312 efficientnet_model.py:143] round_filter input=320 output=384\n","I1202 18:29:10.300499 136091472269312 efficientnet_model.py:143] round_filter input=1280 output=1536\n","I1202 18:29:10.369470 136091472269312 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1202 18:29:10.445304 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I1202 18:29:10.445460 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 224\n","I1202 18:29:10.445537 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n","I1202 18:29:10.447516 136091472269312 efficientnet_model.py:143] round_filter input=32 output=48\n","I1202 18:29:10.472227 136091472269312 efficientnet_model.py:143] round_filter input=32 output=48\n","I1202 18:29:10.472382 136091472269312 efficientnet_model.py:143] round_filter input=16 output=24\n","I1202 18:29:10.631083 136091472269312 efficientnet_model.py:143] round_filter input=16 output=24\n","I1202 18:29:10.631242 136091472269312 efficientnet_model.py:143] round_filter input=24 output=32\n","I1202 18:29:11.026353 136091472269312 efficientnet_model.py:143] round_filter input=24 output=32\n","I1202 18:29:11.026550 136091472269312 efficientnet_model.py:143] round_filter input=40 output=56\n","I1202 18:29:11.618156 136091472269312 efficientnet_model.py:143] round_filter input=40 output=56\n","I1202 18:29:11.618324 136091472269312 efficientnet_model.py:143] round_filter input=80 output=112\n","I1202 18:29:12.553542 136091472269312 efficientnet_model.py:143] round_filter input=80 output=112\n","I1202 18:29:12.553713 136091472269312 efficientnet_model.py:143] round_filter input=112 output=160\n","I1202 18:29:13.269567 136091472269312 efficientnet_model.py:143] round_filter input=112 output=160\n","I1202 18:29:13.269749 136091472269312 efficientnet_model.py:143] round_filter input=192 output=272\n","I1202 18:29:14.354561 136091472269312 efficientnet_model.py:143] round_filter input=192 output=272\n","I1202 18:29:14.354742 136091472269312 efficientnet_model.py:143] round_filter input=320 output=448\n","I1202 18:29:14.725908 136091472269312 efficientnet_model.py:143] round_filter input=1280 output=1792\n","I1202 18:29:14.800193 136091472269312 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1202 18:29:14.883474 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I1202 18:29:14.883633 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 288\n","I1202 18:29:14.883718 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 7\n","I1202 18:29:14.885666 136091472269312 efficientnet_model.py:143] round_filter input=32 output=48\n","I1202 18:29:14.904119 136091472269312 efficientnet_model.py:143] round_filter input=32 output=48\n","I1202 18:29:14.904228 136091472269312 efficientnet_model.py:143] round_filter input=16 output=24\n","I1202 18:29:15.141739 136091472269312 efficientnet_model.py:143] round_filter input=16 output=24\n","I1202 18:29:15.141935 136091472269312 efficientnet_model.py:143] round_filter input=24 output=40\n","I1202 18:29:15.669902 136091472269312 efficientnet_model.py:143] round_filter input=24 output=40\n","I1202 18:29:15.670066 136091472269312 efficientnet_model.py:143] round_filter input=40 output=64\n","I1202 18:29:16.206399 136091472269312 efficientnet_model.py:143] round_filter input=40 output=64\n","I1202 18:29:16.206564 136091472269312 efficientnet_model.py:143] round_filter input=80 output=128\n","I1202 18:29:16.963357 136091472269312 efficientnet_model.py:143] round_filter input=80 output=128\n","I1202 18:29:16.963527 136091472269312 efficientnet_model.py:143] round_filter input=112 output=176\n","I1202 18:29:17.809693 136091472269312 efficientnet_model.py:143] round_filter input=112 output=176\n","I1202 18:29:17.809909 136091472269312 efficientnet_model.py:143] round_filter input=192 output=304\n","I1202 18:29:19.630135 136091472269312 efficientnet_model.py:143] round_filter input=192 output=304\n","I1202 18:29:19.630330 136091472269312 efficientnet_model.py:143] round_filter input=320 output=512\n","I1202 18:29:20.486658 136091472269312 efficientnet_model.py:143] round_filter input=1280 output=2048\n","I1202 18:29:20.611101 136091472269312 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1202 18:29:20.784224 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I1202 18:29:20.784423 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n","I1202 18:29:20.784512 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n","I1202 18:29:20.787825 136091472269312 efficientnet_model.py:143] round_filter input=32 output=56\n","I1202 18:29:20.821075 136091472269312 efficientnet_model.py:143] round_filter input=32 output=56\n","I1202 18:29:20.821230 136091472269312 efficientnet_model.py:143] round_filter input=16 output=32\n","I1202 18:29:21.179414 136091472269312 efficientnet_model.py:143] round_filter input=16 output=32\n","I1202 18:29:21.179609 136091472269312 efficientnet_model.py:143] round_filter input=24 output=40\n","I1202 18:29:21.985810 136091472269312 efficientnet_model.py:143] round_filter input=24 output=40\n","I1202 18:29:21.986006 136091472269312 efficientnet_model.py:143] round_filter input=40 output=72\n","I1202 18:29:22.801703 136091472269312 efficientnet_model.py:143] round_filter input=40 output=72\n","I1202 18:29:22.801878 136091472269312 efficientnet_model.py:143] round_filter input=80 output=144\n","I1202 18:29:23.709320 136091472269312 efficientnet_model.py:143] round_filter input=80 output=144\n","I1202 18:29:23.709488 136091472269312 efficientnet_model.py:143] round_filter input=112 output=200\n","I1202 18:29:24.686999 136091472269312 efficientnet_model.py:143] round_filter input=112 output=200\n","I1202 18:29:24.687167 136091472269312 efficientnet_model.py:143] round_filter input=192 output=344\n","I1202 18:29:26.606270 136091472269312 efficientnet_model.py:143] round_filter input=192 output=344\n","I1202 18:29:26.606431 136091472269312 efficientnet_model.py:143] round_filter input=320 output=576\n","I1202 18:29:27.201812 136091472269312 efficientnet_model.py:143] round_filter input=1280 output=2304\n","I1202 18:29:27.285596 136091472269312 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I1202 18:29:27.399707 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:161] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I1202 18:29:27.399886 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:163] EfficientDet BiFPN num filters: 384\n","I1202 18:29:27.399962 136091472269312 ssd_efficientnet_bifpn_feature_extractor.py:164] EfficientDet BiFPN num iterations: 8\n","I1202 18:29:27.401952 136091472269312 efficientnet_model.py:143] round_filter input=32 output=64\n","I1202 18:29:27.425240 136091472269312 efficientnet_model.py:143] round_filter input=32 output=64\n","I1202 18:29:27.425359 136091472269312 efficientnet_model.py:143] round_filter input=16 output=32\n","I1202 18:29:27.750077 136091472269312 efficientnet_model.py:143] round_filter input=16 output=32\n","I1202 18:29:27.750240 136091472269312 efficientnet_model.py:143] round_filter input=24 output=48\n","I1202 18:29:28.497404 136091472269312 efficientnet_model.py:143] round_filter input=24 output=48\n","I1202 18:29:28.497567 136091472269312 efficientnet_model.py:143] round_filter input=40 output=80\n","I1202 18:29:29.239004 136091472269312 efficientnet_model.py:143] round_filter input=40 output=80\n","I1202 18:29:29.239188 136091472269312 efficientnet_model.py:143] round_filter input=80 output=160\n","I1202 18:29:30.370818 136091472269312 efficientnet_model.py:143] round_filter input=80 output=160\n","I1202 18:29:30.370985 136091472269312 efficientnet_model.py:143] round_filter input=112 output=224\n","I1202 18:29:31.591003 136091472269312 efficientnet_model.py:143] round_filter input=112 output=224\n","I1202 18:29:31.591167 136091472269312 efficientnet_model.py:143] round_filter input=192 output=384\n","I1202 18:29:34.056555 136091472269312 efficientnet_model.py:143] round_filter input=192 output=384\n","I1202 18:29:34.056775 136091472269312 efficientnet_model.py:143] round_filter input=320 output=640\n","I1202 18:29:35.464667 136091472269312 efficientnet_model.py:143] round_filter input=1280 output=2560\n","I1202 18:29:35.616919 136091472269312 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 37.51s\n","I1202 18:29:35.849429 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 37.51s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.02s\n","I1202 18:29:36.069706 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I1202 18:29:36.072276 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I1202 18:29:36.072900 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I1202 18:29:36.075168 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I1202 18:29:36.077120 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I1202 18:29:36.077697 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I1202 18:29:36.079220 136091472269312 test_util.py:2574] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 42.972s\n","\n","OK (skipped=1)\n"]}],"source":["# testing the model builder\n","!python object_detection/builders/model_builder_tf2_test.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1230,"status":"ok","timestamp":1701380384076,"user":{"displayName":"Vanessa Bellotti","userId":"09344672906555327481"},"user_tz":300},"id":"9h0xSPchO8-d","outputId":"c539780e-d253-41cb-abc4-3097f881f6c7"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/gdrive/.shortcut-targets-by-id/1V6R5dIPvEZICGv8F8ogtd3KU8lk3Bltk/MathWorks #2 (BOS) - Classify Object Behavior to Enhance the Safety of Autonomous Vehicles/Datasets_Samples/TransferLearning/nuImg_customOD/data\n","1\t\t\t\t\t\t\timages\t\t test.record\n","annotations\t\t\t\t\t\tlabel_map.pbtxt  train_labels\n","faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.config\ttest_labels\t train_labels.csv\n","faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.tar.gz\ttest_labels.csv  train.record\n"]}],"source":["# !ls ../..\n","%cd ../../Datasets_Samples/TransferLearning/nuImg_customOD/data\n","!ls"]},{"cell_type":"markdown","metadata":{"id":"fYUW7UZejKFb"},"source":["## **6) Create test_labels \u0026 train_labels**\n","Current working directory is '/mydrive/nuImg_customOD/data/'\n","\n","We will now divide annotations into test_labels(20%) and train_labels(80%)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":497,"status":"ok","timestamp":1701380384570,"user":{"displayName":"Vanessa Bellotti","userId":"09344672906555327481"},"user_tz":300},"id":"AoyMt_vssl1j","outputId":"6ee5b97e-1e63-46a6-ffd6-a85d879d1814"},"outputs":[{"name":"stdout","output_type":"stream","text":["mkdir: cannot create directory ‘test_labels’: File exists\n","mkdir: cannot create directory ‘train_labels’: File exists\n","ls: cannot access 'annotations/*': No such file or directory\n","ls: cannot access 'annotations/*': No such file or directory\n"]}],"source":["# Creating two directories for training and testing\n","!mkdir test_labels train_labels\n","\n","# Count the total number of files\n","total_files=!(ls annotations/* | wc -l)\n","\n","# Calculate 20% of the total files\n","twenty_percent=!((total_files * 20 / 100))\n","\n","# Lists the files inside 'annotations' in a random order (not really random, by their hash value instead)\n","# Moves the first 20% labels (20% of the labels) to the testing dir: `test_labels`\n","!ls annotations/* | sort -R | head -$twenty_percent | xargs -I{} mv {} test_labels/\n","# !ls annotations/* | sort -R | head -$twenty_percent | xargs -I{} cp {} test_labels/\n","\n","# Moves the rest of the labels to the training dir: `train_labels`\n","!ls annotations/* | xargs -I{} mv {} train_labels/\n","# !ls annotations/* | xargs -I{} cp {} train_labels/"]},{"cell_type":"markdown","metadata":{"id":"vH67M2M12s3n"},"source":["## **7) Generate TensorFlow record**\n","\n","The TensorFlow Record is Tensorflow’s own binary storage format. If you are working with large datasets, using a binary file format for storage of your data can have a significant impact on the performance of your import pipeline and as a consequence on the training time of your model.\n","\n","Read more here: https://medium.com/mostly-ai/tensorflow-records-what-they-are-and-how-to-use-them-c46bc4bbb564"]},{"cell_type":"markdown","metadata":{"id":"thWKRc-OyYYL"},"source":["### **First, create the CSV files and \"label_map.pbtxt\" file**\n","\n","Run the script in the cell below to create test_labels.csv and train_labels.csv\n","\n","This also creates the label_map.pbtxt file using the classes mentioned in the xml files."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11301,"status":"ok","timestamp":1701380395869,"user":{"displayName":"Vanessa Bellotti","userId":"09344672906555327481"},"user_tz":300},"id":"VyGisGxK4ag0","outputId":"45c91b65-d948-4612-aac5-9777868668f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Successfully converted train_labels xml to csv.\n","Successfully converted test_labels xml to csv.\n","Successfully created label_map.pbtxt \n"]}],"source":["def xml_to_csv(path):\n","  classes_names = []\n","  xml_list = []\n","\n","  for xml_file in glob.glob(path + '/*.xml'):\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","    for member in root.findall('object'):\n","      classes_names.append(member[0].text)\n","      value = (root.find('filename').text  ,\n","               int(root.find('size')[0].text),\n","               int(root.find('size')[1].text),\n","               member[0].text,\n","               int(member[4][0].text),\n","               int(member[4][1].text),\n","               int(member[4][2].text),\n","               int(member[4][3].text))\n","      xml_list.append(value)\n","  column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n","  xml_df = pd.DataFrame(xml_list, columns=column_name)\n","  classes_names = list(set(classes_names))\n","  classes_names.sort()\n","  return xml_df, classes_names\n","\n","for label_path in ['train_labels', 'test_labels']:\n","  image_path = os.path.join(os.getcwd(), label_path)\n","  xml_df, classes = xml_to_csv(label_path)\n","  xml_df.to_csv(f'{label_path}.csv', index=None)\n","  print(f'Successfully converted {label_path} xml to csv.')\n","\n","label_map_path = os.path.join(\"label_map.pbtxt\")\n","pbtxt_content = \"\"\n","\n","for i, class_name in enumerate(classes):\n","    pbtxt_content = (\n","        pbtxt_content\n","        + \"item {{\\n    id: {0}\\n    name: '{1}'\\n}}\\n\\n\".format(i + 1, class_name)\n","    )\n","pbtxt_content = pbtxt_content.strip()\n","with open(label_map_path, \"w\") as f:\n","    f.write(pbtxt_content)\n","    print('Successfully created label_map.pbtxt ')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xDUMKAHhWBy-"},"outputs":[],"source":["!ls images"]},{"cell_type":"markdown","metadata":{"id":"tblFU-i495qr"},"source":["### **Second, create train.record \u0026 test.record files**\n","\n","Current working directory is /mydrive/nuImg_customOD/data/\n","\n","Run the *generate_tfrecord.py* script to create *train.record* and *test.record* files\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17543,"status":"ok","timestamp":1701380413403,"user":{"displayName":"Vanessa Bellotti","userId":"09344672906555327481"},"user_tz":300},"id":"ET4SXdtYUIjZ","outputId":"d8d5def8-fbb3-42cb-d0e4-79c7cbe49671"},"outputs":[{"name":"stdout","output_type":"stream","text":["2023-11-30 21:40:00.818963: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-30 21:40:00.819010: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-30 21:40:00.820277: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-30 21:40:01.883610: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","groups: 100% 20/20 [00:05\u003c00:00,  3.54it/s]\n","Successfully created the TFRecords: /content/gdrive/.shortcut-targets-by-id/1V6R5dIPvEZICGv8F8ogtd3KU8lk3Bltk/MathWorks #2 (BOS) - Classify Object Behavior to Enhance the Safety of Autonomous Vehicles/Datasets_Samples/TransferLearning/nuImg_customOD/data/train.record\n","2023-11-30 21:40:10.749846: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-11-30 21:40:10.749900: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-11-30 21:40:10.751101: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-11-30 21:40:11.798569: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","groups: 100% 19/19 [00:02\u003c00:00,  6.75it/s]\n","Successfully created the TFRecords: /content/gdrive/.shortcut-targets-by-id/1V6R5dIPvEZICGv8F8ogtd3KU8lk3Bltk/MathWorks #2 (BOS) - Classify Object Behavior to Enhance the Safety of Autonomous Vehicles/Datasets_Samples/TransferLearning/nuImg_customOD/data/test.record\n"]}],"source":["#Usage:\n","#!python generate_tfrecord.py output.csv output_pb.txt /path/to/images output.tfrecords\n","\n","#For train.record\n","!python ../../generate_tfrecord.py train_labels.csv  label_map.pbtxt images/ train.record\n","\n","#For test.record\n","!python ../../generate_tfrecord.py test_labels.csv  label_map.pbtxt images/ test.record\n"]},{"cell_type":"markdown","metadata":{"id":"nwWh49ClaBeD"},"source":["## **8) Download pre-trained model checkpoint**\n","\n","Current working directory is /mydrive/nuImg_customOD/data/\n","\n","In the code cell below, we download the .tar.gz file of the model into the ***data*** folder \u0026 unzip it.\n","\n","A list of detection models for tensorflow 2.x can be found [here](https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md).\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"obEW7RNEcowc"},"outputs":[],"source":["# As an example, we will use ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n","\n","#Download the pre-trained model ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz into the data folder \u0026 unzip it.\n","\n","#TODO: CHANGE IT TO FASTER RCNN\n","\n","# !wget http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n","# !tar -xzvf ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n","\n","# Download the pre-trained Faster R-CNN model\n","!wget http://download.tensorflow.org/models/object_detection/tf2/20200711/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.tar.gz\n","!tar faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.tar.gz"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"doYgwRZFZWDS"},"outputs":[],"source":["!ls"]},{"cell_type":"markdown","metadata":{"id":"XS-xqg02X9Ro"},"source":["## **9) Get the model pipeline config file, make changes to it and put it inside the *data* folder**\n","\n","\u003e # ⛔ Attention\n","\u003e In order to run the training, a configuration file needs to be edited. Make sure you follow these instructions\n","\n","Current working directory is /mydrive/nuImg_customOD/data/\n","\n","Copy the model configuration file from ***/content/models/research/object_detection/configs/tf2*** to ***/mydrive/nuImg_customOD/data***\n","\n","In the code below, an example is provided with\n","**ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config**\n","\n","Edit based on the model you want to test.\n","\n","\n","\n","\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nrvsoJPSqO8F"},"outputs":[],"source":["#copy the edited config file from the configs/tf2 directory to the data/ folder in your drive\n","\n","#TODO: CHANGE TO FASTER RCNN\n","#change num_classes to number of your classes.\n","#change test.record path, train.record path \u0026 labelmap path to the paths where you have created these files (paths should be relative to your current working directory while training).\n","#change fine_tune_checkpoint to the path of the directory where the downloaded checkpoint from step 12 is.\n","#change fine_tune_checkpoint_type with value classification or detection depending on the type..\n","#change batch_size to any multiple of 8 depending upon the capability of your GPU. (eg:- 24,128,...,512). Mine is set to 64.\n","#change num_steps to number of steps you want the detector to train.\n","\n","!cp /content/gdrive/MyDrive/MathWorks\\ \\#2\\ \\(BOS\\)\\ -\\ Classify\\ Object\\ Behavior\\ to\\ Enhance\\ the\\ Safety\\ of\\ Autonomous\\ Vehicles//models/research/object_detection/configs/tf2/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.config /mydrive/MathWorks\\ \\#2\\ \\(BOS\\)\\ -\\ Classify\\ Object\\ Behavior\\ to\\ Enhance\\ the\\ Safety\\ of\\ Autonomous\\ Vehicles/Datasets_Samples/TransferLearning/nuImg_customOD/data\n","\n","# maybe this? TODO CHECK\n","\n","# !python model_main_tf2.py --pipeline_config_path=/mydrive/nuImg_customOD/data/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.config --model_dir=/mydrive/nuImg_customOD/training --alsologtostderr\n"]},{"cell_type":"markdown","metadata":{"id":"tr9llb_R1g8y"},"source":["Now, edit the pipeline config file inside the model folder we just copied.\n","\n","**You need to make the following changes:**\n","*   change ***num_classes*** to number of your classes.\n","*   change ***test.record*** path, ***train.record*** path \u0026 ***labelmap*** path to the paths where you have created these files (paths should be relative to your current working directory while training).\n","* change ***fine_tune_checkpoint*** to the path of the directory where the downloaded checkpoint from step 12 is.\n","* change ***fine_tune_checkpoint_type*** with value **classification** or **detection** depending on the type..\n","* change ***batch_size*** to any multiple of 8 depending upon the capability of your GPU.\n","(eg:- 24,128,...,512).Mine is set to 64.\n","* change ***num_steps*** to number of steps you want the detector to train.\n"]},{"cell_type":"markdown","metadata":{"id":"88pz7JpMNRRK"},"source":["## **10) Load Tensorboard**\n","\n","TensorBoard provides the visualization and tooling needed for machine learning experimentation:\n","\n","* Tracking and visualizing metrics such as loss and accuracy\n","* Visualizing the model graph (ops and layers)\n","* Viewing histograms of weights, biases, or other tensors as they change over time\n","* Much more! See more info here: https://www.tensorflow.org/tensorboard"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l-86d0AXNQp7"},"outputs":[],"source":["#load tensorboard\n","\n","%load_ext tensorboard\n","# %tensorboard --logdir '/content/gdrive/MyDrive/nuImg_customOD/training'\n","%tensorboard --logdir '/content/gdrive/MyDrive/MathWorks\\ \\#2\\ \\(BOS\\)\\ -\\ Classify\\ Object\\ Behavior\\ to\\ Enhance\\ the\\ Safety\\ of\\ Autonomous\\ Vehicles/Datasets_Samples/TransferLearning/nuImg_customOD/training'"]},{"cell_type":"markdown","metadata":{"id":"tlzGrIfdAKj9"},"source":["## **11) Train the model**\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"yPmZ2cv17jIj"},"source":["Navigate to the ***object_detection*** folder in colab vm\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-40iq_0ZMgfL"},"outputs":[],"source":["# %cd /content/models/research/object_detection\n","\n","%cd /content/gdrive/MyDrive/MathWorks\\ \\#2\\ \\(BOS\\)\\ -\\ Classify\\ Object\\ Behavior\\ to\\ Enhance\\ the\\ Safety\\ of\\ Autonomous\\ Vehicles/models/research/object_detection"]},{"cell_type":"markdown","metadata":{"id":"_pjP3TuBMjli"},"source":["**11 (a) Training using model_main_tf2.py**\n","\n","Here **{PIPELINE_CONFIG_PATH}** points to the pipeline config and **{MODEL_DIR}** points to the directory in which training checkpoints and events will be written.\n","\n","For best results, you should stop the training when the loss is less than 0.1 if possible, else train the model until the loss does not show any significant change for a while. The ideal loss should be below 0.05 (Try to get the loss as low as possible without overfitting the model. Don’t go too high on training steps to try and lower the loss if the model has already converged viz. if it does not reduce loss significantly any further and takes a while to go down. )"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-B1G668lACEV"},"outputs":[],"source":["# Needed to prevent an existing bug in TensorFlow. Downgrade version running in Colab\n","!pip install tensorflow==2.13.0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7LS0SBCgRuox"},"outputs":[],"source":["# Run the command below from the content/models/research/object_detection directory\n","\"\"\"\n","PIPELINE_CONFIG_PATH=path/to/pipeline.config\n","MODEL_DIR=path to training checkpoints directory\n","NUM_TRAIN_STEPS=50000\n","SAMPLE_1_OF_N_EVAL_EXAMPLES=1\n","\n","python model_main_tf2.py -- \\\n","  --model_dir=$MODEL_DIR --num_train_steps=$NUM_TRAIN_STEPS \\\n","  --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \\\n","  --pipeline_config_path=$PIPELINE_CONFIG_PATH \\\n","  --alsologtostderr\n","\"\"\"\n","#TODO: CHANGE TO FASTER RCNN\n","# !python model_main_tf2.py --pipeline_config_path=/mydrive/nuImg_customOD/data/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.config --model_dir=/mydrive/nuImg_customOD/training --alsologtostderr\n","!python model_main_tf2.py --pipeline_config_path=/content/gdrive/MyDrive/MathWorks\\ \\#2\\ \\(BOS\\)\\ -\\ Classify\\ Object\\ Behavior\\ to\\ Enhance\\ the\\ Safety\\ of\\ Autonomous\\ Vehicles//models/research/object_detection/configs/tf2/faster_rcnn_resnet101_v1_1024x1024_coco17_tpu-8.config --model_dir=/content/gdrive/MyDrive/MathWorks\\ \\#2\\ \\(BOS\\)\\ -\\ Classify\\ Object\\ Behavior\\ to\\ Enhance\\ the\\ Safety\\ of\\ Autonomous\\ Vehicles/Datasets_Samples/TransferLearning/nuImg_customOd/training --alsologtostderr"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6eIzqyxZMCfZ"},"outputs":[],"source":["!python model_main_tf2.py --pipeline_config_path=PATH_TO_CONFIGURE --model_dir=PATH_TO_CONFIGURE --alsologtostderr"]},{"cell_type":"markdown","metadata":{"id":"Nxn-FtdtpsTx"},"source":["## **12) Test your trained model**"]},{"cell_type":"markdown","metadata":{"id":"P9q68YOx3ZPS"},"source":["Export inference graph\n","\n","Current working directory is /content/models/research/object_detection"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OY1l055O3cjJ"},"outputs":[],"source":["## Export inference gra"]}],"metadata":{"accelerator":"GPU","colab":{"name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}