{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"BIQJo2ddCOtP","executionInfo":{"status":"ok","timestamp":1701531051780,"user_tz":300,"elapsed":7332,"user":{"displayName":"Pamela Melgar","userId":"00048250327301414408"}}},"outputs":[],"source":["import os\n","import pathlib\n","import glob\n","import cv2 as cv2\n","import numpy as np\n","import xml.etree.ElementTree as ET\n","import pandas as pd\n","import tensorflow as tf\n","import skimage.io as io\n"]},{"cell_type":"code","source":["# from google.colab import drive\n","\n","# drive.mount('/content/gdrive')\n","\n","# # this creates a symbolic link so that now the path /content/gdrive/My\\ Drive/ is equal to /mydrive\n","# !ln -s \"/content/gdrive/My Drive/\" /mydrive\n","# !ls /mydrive\n","# %cd /mydrive/MathWorks\\ \\#2\\ \\(BOS\\)\\ -\\ Classify\\ Object\\ Behavior\\ to\\ Enhance\\ the\\ Safety\\ of\\ Autonomous\\ Vehicles/\n","# shared_folder_path = '/content/drive/Shared drives/SharedFolderName'"],"metadata":{"id":"_sIKKG-l0o-e","executionInfo":{"status":"ok","timestamp":1701531051781,"user_tz":300,"elapsed":42,"user":{"displayName":"Pamela Melgar","userId":"00048250327301414408"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","execution_count":3,"metadata":{"id":"lv5fWE6UMLH3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1701531064667,"user_tz":300,"elapsed":12924,"user":{"displayName":"Pamela Melgar","userId":"00048250327301414408"}},"outputId":"6c0a5178-5a85-4bf7-ec20-dbb09863065a"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-12-02 15:30:51--  https://www.nuscenes.org/data/nuimages-v1.0-mini.tgz\n","Resolving www.nuscenes.org (www.nuscenes.org)... 18.64.174.36, 18.64.174.116, 18.64.174.111, ...\n","Connecting to www.nuscenes.org (www.nuscenes.org)|18.64.174.36|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 117929607 (112M) [application/x-tar]\n","Saving to: ‘nuimages-v1.0-mini.tgz.1’\n","\n","nuimages-v1.0-mini. 100%[===================>] 112.47M  32.2MB/s    in 3.5s    \n","\n","2023-12-02 15:30:55 (32.2 MB/s) - ‘nuimages-v1.0-mini.tgz.1’ saved [117929607/117929607]\n","\n"]}],"source":["!mkdir -p /data/sets/nuimages  # Make the directory to store the nuImages dataset in.\n","\n","!wget https://www.nuscenes.org/data/nuimages-v1.0-mini.tgz  # Download the nuImages mini split.\n","\n","!tar -xf nuimages-v1.0-mini.tgz -C /data/sets/nuimages  # Uncompress the nuImages mini split.\n","\n","!pip install nuscenes-devkit &> /dev/null  # Install nuImages."]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":181,"status":"ok","timestamp":1701531064835,"user":{"displayName":"Pamela Melgar","userId":"00048250327301414408"},"user_tz":300},"id":"RWvITfZ6NDhl","outputId":"0aefcf61-84b7-4c83-b817-5a89a1b55d7f"},"outputs":[{"output_type":"stream","name":"stdout","text":["======\n","Loading nuImages tables for version v1.0-mini...\n","Done loading in 0.000 seconds (lazy=True).\n","======\n"]}],"source":["%matplotlib inline\n","%load_ext autoreload\n","%autoreload 2\n","from nuimages import NuImages\n","\n","nuim = NuImages(dataroot='/data/sets/nuimages', version='v1.0-mini', verbose=True, lazy=True)"]},{"cell_type":"markdown","source":["##Insert the Basepath for /images and XML /annotations folder to be stored::\n","\n","---\n","\n"],"metadata":{"id":"q7MQq4FmACDh"}},{"cell_type":"code","source":["DATA_BASEPATH = '/content/sample_data/'\n","NUM_IMAGES_FROM_DATASET = 50"],"metadata":{"id":"VnaEmLMzS8Gr","executionInfo":{"status":"ok","timestamp":1701531065031,"user_tz":300,"elapsed":200,"user":{"displayName":"Pamela Melgar","userId":"00048250327301414408"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["images_we_want = [\n","    sample for sample in nuim.sample[NUM_IMAGES_FROM_DATASET:]\n","    if any(\n","        any(\"cycle.with_rider\" in nuim.get('attribute', att_token)['name'] or \"pedestrian\" in nuim.get('attribute', att_token)['name']\n","            for att_token in nuim.get('object_ann', o)['attribute_tokens'])\n","        for o in nuim.list_anns(sample['token'], verbose=False)[0]\n","    )\n","]\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GHeRjA0VLDGq","executionInfo":{"status":"ok","timestamp":1701531065032,"user_tz":300,"elapsed":20,"user":{"displayName":"Pamela Melgar","userId":"00048250327301414408"}},"outputId":"f4158a31-34e7-466d-d866-ad19b64e8b14"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Loaded 50 sample(s) in 0.000s,\n"]}]},{"cell_type":"markdown","source":["##Create folders for (filtered) images and corresponding XML files (image object annotations)"],"metadata":{"id":"dIFhhLahBGuM"}},{"cell_type":"code","execution_count":7,"metadata":{"id":"cNfA8V6jkvkZ","executionInfo":{"status":"ok","timestamp":1701531065199,"user_tz":300,"elapsed":175,"user":{"displayName":"Pamela Melgar","userId":"00048250327301414408"}}},"outputs":[],"source":["import os\n","from lxml import etree as ET\n","\n","# Parent Directory paths\n","parent_dir = DATA_BASEPATH+'images'\n","parent_dir_xmls = DATA_BASEPATH+'annotations'\n","\n","# parent_dir = \"/content/sample_data/images\"\n","# parent_dir_xmls = \"/content/sample_data/annotations\"\n","\n","# Path\n","try:\n","  os.mkdir(parent_dir)\n","except FileExistsError:\n","  pass\n","\n","try:\n","  os.mkdir(parent_dir_xmls)\n","except FileExistsError:\n","  pass"]},{"cell_type":"markdown","metadata":{"id":"pHcvxdX12NNL"},"source":["# XML Conversion Below"]},{"cell_type":"markdown","source":["###Takes a single object annotation in an image and extracts necessary XML annotation information\n","###(bounding box + label)"],"metadata":{"id":"bkeUCdZxBpy5"}},{"cell_type":"code","execution_count":8,"metadata":{"id":"fxXqIN9uvWkE","executionInfo":{"status":"ok","timestamp":1701531065402,"user_tz":300,"elapsed":208,"user":{"displayName":"Pamela Melgar","userId":"00048250327301414408"}}},"outputs":[],"source":["def retrieve_object_annotation_components(object_token):\n","  object_record = nuim.get('object_ann', object_token)\n","  x_min, y_min, x_max, y_max = object_record['bbox'] #<int> [4] -- Annotated amodal bounding box. Given as [xmin, ymin, xmax, ymax].\n","\n","  category_token = object_record['category_token']\n","  curr_object_label = nuim.get('category', category_token)['name'] #This will be the <name> of our object for XML\n","\n","  return x_min, x_max, y_min, y_max, curr_object_label"]},{"cell_type":"markdown","source":["###XML code below + stores into annotations folder"],"metadata":{"id":"_M--1AvXCD0x"}},{"cell_type":"code","execution_count":9,"metadata":{"id":"gT_Gv6ySyvoN","executionInfo":{"status":"ok","timestamp":1701531065576,"user_tz":300,"elapsed":180,"user":{"displayName":"Pamela Melgar","userId":"00048250327301414408"}}},"outputs":[],"source":["def write_xml_annotation_clean(object_tokens, height, width, path, image_filename):\n","    annotation = ET.Element(\"annotation\")\n","\n","    folder = ET.SubElement(annotation, \"folder\")\n","    folder.text = str('annotations')\n","\n","    filename = ET.SubElement(annotation, \"filename\")\n","    filename.text = str(image_filename)\n","\n","    path_elem = ET.SubElement(annotation, \"path\")\n","    path_elem.text = path\n","\n","    directory_elem = ET.SubElement(annotation, \"directory\")\n","    # directory_elem.text = os.path.join('/', *path.split('/')[:-1])\n","    directory_elem.text = os.path.join('/', path)\n","\n","\n","    size = ET.SubElement(annotation, \"size\")\n","    width_elem = ET.SubElement(size, \"width\")\n","    width_elem.text = str(width)\n","\n","    height_elem = ET.SubElement(size, \"height\")\n","    height_elem.text = str(height)\n","\n","    depth_elem = ET.SubElement(size, \"depth\") # color channels RGB (3) assume\n","    depth_elem.text = str(3)\n","\n","\n","    #This is for a single object annotation in the image\n","    for single_object_token in object_tokens:\n","      x_min, x_max, y_min, y_max, curr_object_label = retrieve_object_annotation_components(single_object_token)\n","      object_elem = ET.SubElement(annotation, \"object\")\n","\n","      name = ET.SubElement(object_elem, \"name\")\n","      name.text = str(curr_object_label)\n","\n","      pose = ET.SubElement(object_elem, \"pose\")\n","      pose.text = str('Unspecified')\n","\n","      truncated = ET.SubElement(object_elem, \"truncated\")\n","      truncated.text = str(0)\n","\n","      difficult = ET.SubElement(object_elem, \"difficult\")\n","      difficult.text = str(0)\n","\n","      bndbox = ET.SubElement(object_elem, \"bndbox\")\n","\n","      xmin = ET.SubElement(bndbox, \"xmin\")\n","      xmin.text = str(x_min)\n","\n","      ymin = ET.SubElement(bndbox, \"ymin\")\n","      ymin.text = str(y_min)\n","\n","      xmax = ET.SubElement(bndbox, \"xmax\")\n","      xmax.text = str(x_max)\n","\n","      ymax = ET.SubElement(bndbox, \"ymax\")\n","      ymax.text = str(y_max)\n","\n","    # Convert the XML tree to a byte string\n","    xml_string = ET.tostring(annotation, pretty_print=True, xml_declaration=True, encoding=\"UTF-8\")\n","\n","    # XML Directory path\n","    # e.g:   xml_dir = \"/content/sample_data/annotations\"\n","    xml_dir = DATA_BASEPATH + 'annotations'\n","\n","\n","    # Name of the XML file\n","    newXMLFilename = image_filename.split('.')[0] + '.xml'\n","\n","    # You can also save this XML to a file\n","    path_to_xml = os.path.join(xml_dir, newXMLFilename)  # Replace with your desired file path\n","    with open(path_to_xml, \"wb\") as xml_file:\n","        xml_file.write(xml_string)\n","\n","    return path_to_xml"]},{"cell_type":"markdown","source":["###Create XML for entire image - gathers necessary information from image contents and calls the XML Annotation function above"],"metadata":{"id":"b1dg0EApaPWS"}},{"cell_type":"code","source":["def create_XML_for_single_image(sample_record):\n","    sample_data_record = nuim.get('sample_data', sample_record['key_camera_token'])\n","    image_filename = os.path.basename(sample_data_record['filename'])\n","    path = os.path.join(parent_dir, image_filename)\n","    height = sample_data_record['height']\n","    width = sample_data_record['width']\n","\n","    object_tokens, _ = nuim.list_anns(sample_record['token'], verbose=False)\n","\n","    #Despite having image with pedestrians/cyclist - XML should only contain\n","    #annotations with pedestrians\n","    o_we_want = [\n","        o for o in object_tokens\n","        for att_token in nuim.get('object_ann', o)['attribute_tokens']\n","        if any(\"cycle.with_rider\" in nuim.get('attribute', att_token)['name']\n","               or \"pedestrian\" in nuim.get('attribute', att_token)['name']\n","               for att_token in [att_token])\n","    ]\n","\n","    write_xml_annotation_clean(o_we_want, height, width, path, image_filename)\n","    return\n"],"metadata":{"id":"2dfapLKVJOa8","executionInfo":{"status":"ok","timestamp":1701531065577,"user_tz":300,"elapsed":8,"user":{"displayName":"Pamela Melgar","userId":"00048250327301414408"}}},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":["###Renders an image into /images folder"],"metadata":{"id":"tgVmQ-MRDNh5"}},{"cell_type":"code","execution_count":11,"metadata":{"id":"IcGvYBAEx_k7","executionInfo":{"status":"ok","timestamp":1701531065577,"user_tz":300,"elapsed":7,"user":{"displayName":"Pamela Melgar","userId":"00048250327301414408"}}},"outputs":[],"source":["def store_single_image(sample_record):\n","  sample_data_record = nuim.get('sample_data', sample_record['key_camera_token'])\n","\n","  image_filename = os.path.basename(sample_data_record['filename']) #extract the imagename.jpg from the 'filename', currently includes extra 'stuff' in the name\n","  nuim.render_image(sample_record['key_camera_token'], annotation_type='none', out_path=DATA_BASEPATH+'images/' + image_filename) #download IMAGE with no annotations on it\n"]},{"cell_type":"markdown","metadata":{"id":"bF-p5il32cdx"},"source":["Generates images (filtered) and corresponding XMLs"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":166,"status":"ok","timestamp":1701531065737,"user":{"displayName":"Pamela Melgar","userId":"00048250327301414408"},"user_tz":300},"id":"6AkCF1TOzNeV","outputId":"d980d4ac-617d-4e75-8319-8d53cc038dbf"},"outputs":[{"output_type":"stream","name":"stdout","text":["images render and XML generation complete :-) \n","Stored in /content/sample_data/images/ and /content/sample_data/annotations/\n"]}],"source":["# Create image along with its matching XML files\n","\n","for sample in images_we_want:\n","  create_XML_for_single_image(sample)\n","  store_single_image(sample)\n","\n","print(\"images render and XML generation complete :-) \")\n","print(\"Stored in \" + DATA_BASEPATH + \"images/ and \" + DATA_BASEPATH + \"annotations/\")"]},{"cell_type":"markdown","metadata":{"id":"I6dj6kLcEU-M"},"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1jw-F1mAFZ1oLLSJKoc4xQjEWEHgrMJFn","timestamp":1696981999842}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}